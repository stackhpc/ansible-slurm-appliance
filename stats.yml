---
# NOTE: Requires slurmdbd

- name: Install dependenices
  hosts: podman
  tasks:
    - name: Install OS packages
      yum:
        name:
          - podman
          - python3
        state: installed
      become: true

    - name: Up default resource limits
      copy:
        content: |
          # WARNING: This file is managed by ansible, do not modify.
          # This is so non-root containers can use more resources. This is useful
          # for opendistro.
          * soft memlock unlimited
          * hard memlock unlimited
          * soft nofile 65536
          * hard nofile 65536
        dest: /etc/security/limits.d/custom.conf
      become: true

    - name: Setup a pod
      containers.podman.podman_pod:
        name: elastic
        state: started
        ports:
          - 9200:9200
          - 9600:9600
          - 5601:5601

- name: Setup elasticsearch
  hosts: elastic
  tasks:
    - name: Ensure parent directory exists
      file:
        state: directory
        path: "/etc/elastic"
        owner: "1000"
        group: "1000"
        mode: 0770
      become: true

    - name: Template configuration files
      template:
          src: config/elastic/internal_users.yml
          dest: /etc/elastic/internal_users.yml
          owner: "1000"
          group: "1000"
          mode: 0600
      # This needs to smarter as bcrypt hash changes everytime
      notify: Restart opendistro container
      become: true

    - name: Setup volume for opendistro
      containers.podman.podman_volume:
        state: present
        name: opendistro

    - name: Setup opendistro
      containers.podman.podman_container:
        name: opendistro
        image: amazon/opendistro-for-elasticsearch:1.11.0
        state: started
        pod: elastic
        restart_policy: "always"
        ulimit:
          - memlock=-1:-1
          # maximum number of open files for the Elasticsearch user, set to at least 65536 on modern systems
          - nofile=65536:65536
        volume:
          - opendistro:/usr/share/elasticsearch/data
          - /etc/elastic/internal_users.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/internal_users.yml
        env:
          node.name: opendistro
          discovery.type: single-node
          bootstrap.memory_lock: "true" # along with the memlock settings below, disables swapping
          ES_JAVA_OPTS: -Xms512m -Xmx512m # minimum and maximum Java heap size, recommend setting both to 50% of system RAM

  handlers:
    - name: Restart opendistro container
      command: podman restart opendistro

- name: Setup kibana
  hosts: kibana
  tasks:
    - name: Setup volume for kibana
      containers.podman.podman_volume:
        state: present
        name: kibana

    - name: Setup kibana
      containers.podman.podman_container:
        image: amazon/opendistro-for-elasticsearch-kibana:1.11.0
        name: kibana
        state: started
        pod: elastic
        restart_policy: "always"
        expose:
          - "5601"
        env:
          # FIXME: assumes same host as elastic
          ELASTICSEARCH_URL: https://localhost:9200
          ELASTICSEARCH_HOSTS: https://localhost:9200
          ELASTICSEARCH_USERNAME: admin
          ELASTICSEARCH_PASSWORD: "{{ secrets_openhpc_elasticsearch_admin_password }}"

    - name: Wait for kibana to start listening
      wait_for:
        port: 5601
        delay: 5

    - name: Wait for kibana to be ready
      uri:
        url: http://localhost:5601/api/kibana/settings
        method: GET
        user: admin
        password: "{{ secrets_openhpc_elasticsearch_admin_password }}"
        force_basic_auth: yes
      register: response
      until: "'kbn_name' in response and response.status == 200"
      retries: 1
      delay: 5

    - name: Add filebeat index
      vars:
        index_pattern:
          attributes:
            title: "filebeat-*"
            timeFieldName: "@timestamp"
      uri:
        url: "http://localhost:5601/api/saved_objects/index-pattern/filebeat-*?overwrite=true"
        method: POST
        user: admin
        password: "{{ secrets_openhpc_elasticsearch_admin_password }}"
        force_basic_auth: yes
        body_format: json
        body: "{{ index_pattern }}"
        headers:
          kbn-xsrf: anything

- name: Setup slurm stats
  hosts: slurm_stats
  collections:
    - stackhpc.slurm_openstack_tools
  tasks:

    - include_role:
        name: slurm-stats
        apply:
          # Collection currently requires root for all tasks.
          become: true

    - name: Ensure parent directory exists
      file:
        state: directory
        path: "/etc/filebeat"
        owner: "1000"
        group: "1000"
        mode: 0770
      become: true

    - name: Template configuration files
      template:
          src: config/filebeat/filebeat.yml
          dest: /etc/filebeat/filebeat.yml
          owner: "1000"
          group: "1000"
          mode: 0600
      notify: Restart filebeat container
      become: true

    - name: Setup file beat
      containers.podman.podman_container:
        image: docker.elastic.co/beats/filebeat-oss:7.9.3
        name: filebeat
        state: started
        # FIXME: /usr/share/filebeat/filebeat is owned by root:root and 0750 - podman only?
        # Unsure how this works in docker as the permissions are identical.
        user: root
        pod: elastic
        restart_policy: "always"
        security_opt:
          # Required to read /var/log. There might be a better solution, see:https://github.com/containers/podman/issues/3683
          - label=disable
        volumes:
          - /var/log/:/logs:ro
          - /etc/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
        command: -e -strict.perms=false -d "*"

  handlers:
    - name: Restart filebeat container
      command: podman restart filebeat
# Must be within K3s' reserved port range (default 30000-32767)
prometheus_port: 30000

prometheus_db_dir: "{{ appliances_state_dir }}/prometheus"
prometheus_storage_retention: "30d"
prometheus_storage_retention_size: "40GB"
prometheus_scrape_configs_default:
- job_name: "slurm_exporter"
  scrape_interval: 30s
  scrape_timeout: 30s
  static_configs:
    - targets:
      - "{{ control_ip }}:{{ slurm_exporter_port }}"
  relabel_configs:
  # strip off port
  - source_labels: ['__address__']
    separator:     ':'
    regex:         '(.*):.*'
    target_label:  'instance'
    replacement:   '${1}'

prometheus_scrape_configs: "{{ prometheus_scrape_configs_default + (openondemand_scrape_configs if groups['openondemand'] | count > 0 else []) }}"
prometheus_extra_rules:
  - alert: SlurmNodeDown
    annotations:
      description: '{% raw %}{{ $value }} Slurm nodes are in down status.{% endraw %}'
      summary: 'At least one Slurm node is down.'
    expr: "slurm_nodes_down > 0\n"
    labels:
      severity: critical
  - alert: BlackboxProbeFailed
    expr: probe_success == 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Blackbox probe failed (target {{ $labels.target }}){% endraw %}'
      description: "{% raw %}Blackbox probe '{{ $labels.target }}' failed{% endraw %}"
  - alert: BlackboxSlowProbe
    expr: avg_over_time(probe_duration_seconds[1m]) > 1.2 #around 1.14 expected due to indirection in cluster
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}Blackbox slow probe (target {{ $labels.target }}){% endraw %}'
      description: "{% raw %}Blackbox probe '{{ $labels.target }}' took more than 1s to complete - {{ $value }}{% endraw %}"
  - alert: BlackboxProbeHttpFailure
    expr: probe_http_status_code <= 199 OR probe_http_status_code >= 400
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Blackbox probe HTTP failure (target {{ $labels.target }}){% endraw %}'
      description: "{% raw %}Blackbox probe '{{ $labels.target }}' returned an HTTP error status - {{ $value }}{% endraw %}"
  - alert: BlackboxSslCertificateWillExpireSoon
    expr: (7 * 24 * 3600) <= (last_over_time(probe_ssl_earliest_cert_expiry[10m]) - time()) < (30 * 24 * 3600)
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}Blackbox SSL certificate will expire soon (target {{ $labels.target }}){% endraw %}'
      description: "{% raw %}SSL certificate for blackbox probe '{{ $labels.target }}' expires in {{ $value | humanizeDuration }}{% endraw %}"
  - alert: BlackboxSslCertificateWillExpireVerySoon
    expr: 0 <= (last_over_time(probe_ssl_earliest_cert_expiry[10m]) - time()) < (7 * 24 * 3600)
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Blackbox SSL certificate will expire very soon (target {{ $labels.target }}){% endraw %}'
      description: "{% raw %}SSL certificate for blackbox probe '{{ $labels.target }}' expires in {{ $value | humanizeDuration }}{% endraw %}"
  - alert: BlackboxSslCertificateExpired
    expr: (last_over_time(probe_ssl_earliest_cert_expiry[10m]) - time()) < 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Blackbox SSL certificate expired (target {{ $labels.target }}){% endraw %}'
      description: "{% raw %}SSL certificate for blackbox probe '{{ $labels.target }}' has expired{% endraw %}"
  - record: node_cpu_system_seconds:record
    expr: (100 * sum by(instance)(increase(node_cpu_seconds_total{mode="system",job="node-exporter"}[60s]))) / (sum by(instance)(increase(node_cpu_seconds_total{job="node-exporter"}[60s])))
  - record: node_cpu_user_seconds:record
    expr: (100 * sum by(instance)(increase(node_cpu_seconds_total{mode="user",job="node-exporter"}[60s]))) / (sum by(instance)(increase(node_cpu_seconds_total{job="node-exporter"}[60s])))
  - record: node_cpu_iowait_seconds:record
    expr: (100 * sum by(instance)(increase(node_cpu_seconds_total{mode="iowait",job="node-exporter"}[60s]))) / (sum by(instance)(increase(node_cpu_seconds_total{job="node-exporter"}[60s])))
  - record: node_cpu_other_seconds:record
    expr: (100 * sum by(instance)(increase(node_cpu_seconds_total{mode!="idle",mode!="user",mode!="system",mode!="iowait",job="node-exporter"}[60s]))) / (sum by(instance)(increase(node_cpu_seconds_total{job="node-exporter"}[60s])))
  - record: node_cpu_scaling_frequency_hertz_avg:record # Warning: frequency rules will not work when deploying appliance on VMs
    expr: avg by (instance) (node_cpu_scaling_frequency_hertz)
  - record: node_cpu_scaling_frequency_hertz_min:record
    expr: min by (instance) (node_cpu_scaling_frequency_hertz)
  - record: node_cpu_scaling_frequency_hertz_max:record
    expr: max by (instance) (node_cpu_scaling_frequency_hertz)

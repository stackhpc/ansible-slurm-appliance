---

# See: https://github.com/cloudalchemy/ansible-prometheus
# for variable definitions

prometheus_version: 2.27.0 # default from ansible/roles/cloudalchemy.prometheus/defaults/main.yml
prometheus_web_external_url: "http://{{ hostvars[groups['prometheus'].0].ansible_host }}:9090/" # default to host IP address
prometheus_storage_retention: "31d"
prometheus_storage_retention_size: "100GB"
prometheus_db_dir: "{{ appliances_state_dir | default('/var/lib') }}/prometheus"

prometheus_alertmanager_config_default:
  - static_configs:
    - targets:
      - "{{ alertmanager_address }}:{{ alertmanager_port }}"
    basic_auth:
      username: alertmanager
      password: "{{ vault_alertmanager_admin_password }}"

prometheus_alertmanager_config_extra: []
prometheus_alertmanager_config: "{{ (prometheus_alertmanager_config_default if groups['alertmanager'] else []) + prometheus_alertmanager_config_extra }}"

# By default, find rule files from the following path relative to current and all parent environment inventory directories:
# Note: If the same file exists in parent and child environments, only the file in the latter has any effect.
prometheus_alert_rules_files_inventory_glob: ../files/prometheus/rules/*.rules
prometheus_alert_rules_files: "{{ ansible_inventory_sources | product([prometheus_alert_rules_files_inventory_glob]) | map('join', '/') | map('realpath') }}"

prometheus_alert_rules:
  - alert: SlurmDBDQueueLarge
    # NB: {{ templates }} in annotations.description are interpolated by prometheus, in expr by ansible
    annotations:
      description: '{% raw %}Slurm DBD message queue size {{ $value }} is larger than half Slurm parameter MaxDBDMsgs - check database health{% endraw %}'
      summary: 'Slurm DBD message queue is large.'
    expr: "slurm_scheduler_dbd_queue_size > {{ hostvars[groups['control'].0].ansible_local.slurm.MaxDBDMsgs | int }}"

# Can set a hostvar 'prometheus_env' to an arbitrary string to group prometheus targets, e.g. by rack.
prometheus_targets:
  control: "{{ groups.get('node_exporter', []) | intersect(groups['control']) | prometheus_node_exporter_targets(hostvars, 'prometheus_env', 'control') }}"
  login: "{{ groups.get('node_exporter', []) | intersect(groups['login']) | prometheus_node_exporter_targets(hostvars, 'prometheus_env', 'login') }}"
  compute: "{{ groups.get('node_exporter', []) | intersect(groups['compute']) | prometheus_node_exporter_targets(hostvars, 'prometheus_env', 'compute') }}"
  # openhpc is defined as control+login+compute so this gets any other node exporter targets:
  other: "{{ groups.get('node_exporter', []) | difference(groups['openhpc']) | prometheus_node_exporter_targets(hostvars, 'prometheus_env', 'other') }}"

prometheus_scrape_configs_default:
- job_name: "prometheus"
  metrics_path: "/metrics"
  static_configs:
  - targets:
    - "{{ prometheus_address }}:9090"
- job_name: "grafana"
  static_configs:
  - targets:
    - "{{ grafana_api_address }}:{{ grafana_port }}"
- job_name: "node"
  file_sd_configs:
  - files:
    - /etc/prometheus/file_sd/control.yml
    - /etc/prometheus/file_sd/login.yml
    - /etc/prometheus/file_sd/compute.yml
    - /etc/prometheus/file_sd/other.yml
  relabel_configs:
  # strip off port
  - source_labels: ['__address__']
    separator:     ':'
    regex:         '(.*):.*'
    target_label:  'instance'
    replacement:   '${1}'
  scrape_interval: 30s
  scrape_timeout: 20s

- job_name: "slurm_exporter"
  scrape_interval: 30s
  scrape_timeout: 30s
  static_configs:
    - targets:
      - "{{ openhpc_slurm_control_host }}:{{ slurm_exporter_port }}"

prometheus_scrape_configs: "{{ prometheus_scrape_configs_default + (openondemand_scrape_configs if groups['openondemand'] | count > 0 else []) }}"
